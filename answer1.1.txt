[stuff at top of answer1 should go in scientific question1.1]

So here's the problem. If we consider this to be a scientific question, then basically no one has a clue to what the answer to it is. Worse, the question is so general that it's difficult to find something that all situations like this have in common, and even if we came up with a guess of how to answer it, the people able to measure the answer a few decades from now would be unable to tell the rest of us the answer in a way that is helpful to us! So given that, what approaches can we take to try to answer this problem?

Well, consider what you would do if you were in that situation. Since we probably won't be able to perform this experiment for at least a few more decades, hopefully the scientific community will have one or more pretty good guesses of what you'll perceive happening by then. (Or perhaps the scientific community won't think that the question is scientific, but as stated earlier [state it earlier], I'm working on the assumption from now on that we do consider this to be scientific.) But since this will be the first time that you will be able to compare these predictions to observations, you should be very open to the possibility that these guesses will be wrong. And if it does turn out that these guesses are wrong, you should come up with your own guesses of what you will perceive happening, and continue the cycle of testing predictions and making new ones until you have a way of making predictions that seems to work.

So what would be the most useful thing to tell you if you were to be put in that situation? As for me personally, I'd imagine that a lot of what would happen to you would depend on the specific simulation you're put in, though a 50% chance of seeing a red flash and a 50% chance of seeing a green flash seems like a reasonable initial guess for the situation described previously. But if I were you, I wouldn't put much weight on that because I haven't experimentally verified that. [I just said the same thing 3 times] Indeed, since that would be the case for everyone else predicting what you would perceive happening the first time you're in that situation, it almost seems like the most useful thing to tell you would not be people's initial guesses of the probability of you seeing a red or green flash, but rather how you can quickly learn from the results once you start measuring them.

As it turns out, there is an entire field of study dedicated to studying processes that can be used to predict future outcomes from past ones. An important result that these people have mathematically proven is that there is one such way of doing this called algorithmic probability that is, in a certain sense, "optimal!" The trouble is that it is impossible to calculate algorithmic probability with computers as we know them today because any computer program that tries to calculate it would run forever without ever producing a result, so there is an entire field of machine learning dedicated to finding more approximate learning algorithms that are practical to run on computers. But even though algorithmic probability is more or less impossible to use in practice, I think it is good to know it anyway because it's relatively simple and because it's pretty much the gold standard for inductive inference as long as you're not concerned about actually calculating it. So if we could hypothetically calculate it, how could it be applied to predict whether you'll see a red or green flash?

First of all, it's worth noting that even if we could calculate algorithmic probability, it would only be useful if we ran the color flashing experiment many times because the first few probabilities we'd come up with would be gibberish. Only when we have prior knowledge of previous outcomes can we take that knowledge into account in our predictions. So let's modify the setup accordingly. After putting the test subject (which might be you or me) in a computer simulation using the process described earlier, we pause the simulation, copy it onto a second computer, resume it on both computers, then flash red in the first computer and green in the second computer. (Or we could do the variation where we copy the simulation to 2 more computers, blow up the original computer, then flash red in the second computer and green in the third computer.) But this time we don't stop there. Next, we do the same thing to both computers. In other words, if we flashed red in computer A and green in computer B, we copy computer A's state to a new computer C, copy computer B's state into a new computer D, flash red in computers A and B, and flash green in computers C and D. Then we keep repeating this process of copying the simulation states into new computers, flashing red in the originals and flashing green in the copies, until we run out of computers or funding or whatever.

[picture]

Now in order to bring algorithmic probability into the picture, we first need to introduce the concept of bitstrings. When you have a string of text, that text is stored in the computer as a sequence of 1's and 0's called a bitstring. To convert the bitstring to characters, you apply something called a character encoding. One common encoding is called ASCII, and to convert a bitstring to ASCII characters, you separate the bitstring into 8 bit chunks called bytes, and use a table to find the character corresponding to each byte.

So here's how to determine the algorithmic probability that the person in the simulation will see a particular sequence of colored flashes. Suppose we make a bitstring by repeatedly flipping a fair coin, writing 0 each time we get heads and 1 each time we get tails. (By fair coin, I mean that each flip has a 50% chance of being heads or tails and every flip is independent of the others.) We stop flipping coins when the last byte in the sequence corresponds to some arbitrary unprintable character. (A good choice might be the "end of transmission" ASCII character.) Then we pretend that this randomly generated string is actually a C program and *try to compile it*. In the highly unlikely case that compilation succeeds, we run the resulting program and see what it prints out to the console. Now this console output can be considered a bitstring too, so we take 0 to mean "red flash" and 1 to mean "green flash." Then the algorithmic probability that the person in the simulation will see a particular sequence of colored flashes is the probability that a console output bitstring generated this way begins with that particular sequence. [reword last sentence; also this has same problem that some outputs long enough for some probs but not others, no good way to prevent b/c any univ turing machine can go into infinite loop that doesn't print anything, can this be rationalized]

Isn't that ridiculous? In essence, the algorithmic probability of a bitstring (which can be interpreted as a sequence of red and green flashes) is the probability that it is the beginning of the output of a randomly generated program!

Now of course, you may wonder, is that *really* the probability of what might happen to us if we put ourselves in a computer simulation and couldn't tell which computer we were in?

Honestly, I don't know. The only reason I bring up this possibility is because if it's possible to answer that question by experiment, then as far as I can tell the scientific community does not have an agreed upon prediction of what the answer to it is. And as someone who is likely to see these super-powerful computers exist in my lifetime, I feel we have an obligation to try to answer it, or at least participate in wild-eyed speculation of what the consequences would be. I am just trying to start that discussion. So please do not consider me to be an authority or representative of the scientific community on this subject (because I'm not), and if you want to add to this discussion, I'm more than happy to hear what your thoughts are.

But it's worth mentioning a few things about using algorithmic probability this way.

[is this actually a semi measure? yes according to http://scholarpedia.org/article/Algorithmic_probability, no according to https://en.wikipedia.org/wiki/Solomonoff's_theory_of_inductive_inference]

For one, you could do the same procedure with a different Turing complete language than C and get different resulting probabilities, and that would still be considered "algorithmic probability."

I know what you're thinking. "See, algorithmic probability isn't unique. So even if these probabilities can be determined by experiment in the first place, algorithmic probability can't even tell me what are the 'right' probabilities to expect. So this isn't scientific."

Well, not so fast. No matter which programming language you pick, all these different choices of algorithmic probability have more in common than you might expect, and here's why. We know that somewhere in the randomly generated C code (I'm using C as a sample language for now), there is some code that is a variation of the following, otherwise it wouldn't compile:

int main() {
	// some code here
}

[or just use how we determine when program ends]

[non-unique probabilities, converging (and why), only way to get result faster would be by overfitting, classifying result that doesn't fit, lead in to prior info]
