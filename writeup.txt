Putting someone in virtual reality

For the last several decades, computing power has essentially grown at an exponential rate, and it always looked as if in about 10 years into the future we would run into some seemingly unsurmountable problem that would prevent computing power from significantly increasing beyond that. But each time that prediction was made, sometime later people would find a solution to that! So people have tried to predict how long it would take until computers become as smart as every human on earth if this trend continued, making a ton of dubious assumptions in the process, but most people who've done that ended up with a number around a timeframe from about 2020 to 2060. [http://library.fora.tv/2012/10/14/Stuart_Armstrong_How_Were_Predicting_AI at 10:15] That's probably within my lifetime! So it's fun to speculate about what these computers from around 2060 would be capable of. Even if those predictions are wrong and it takes much longer for computers to become that smart, it's fun to speculate about what really powerful computers would be capable of anyway.

Virtual reality simulations are already pretty good these days. I'd imagine that virtual reality simulations around 2060 would be *really* good, possibly so good that to a virtual person living in one, it would look pretty convincingly like a real universe. Now the simulation doesn't have to be programmed to behave anything like our universe. Our universe behaves with some sort of combination of general relativity and the standard model, but the simulation doesn't have to behave that way and people in the future could program it to behave any way they wanted. That said, if we wanted to predict what the simulation would do, we could still in theory measure the states that all of the particles in the computer were in, and use the standard model and general relativity (or even just look at the computer program and the hardware specs) to get a pretty damn good idea of how the simulation would behave. So no surprises there.

But still, wouldn't it be fun to live in one of these simulations that doesn't have to behave like our universe? Perhaps it could be done like this. People have already done experiments where they put implants into rat brains and had them communicate with each other. [http://www.guardian.co.uk/science/2013/feb/28/brains-rats-connected-share-information] In 2060, it wouldn't be too much of a stretch to suppose that people could do this with human brains as well [add updated link], and that there could be so much bandwidth transfer between the brains that people hooked up this way would feel like a single person. After all, single celled organisms came before multicellular organisms, and you can think of multicellular organisms such as us as a bunch of single-celled organisms hooked up in such a way that they're dependent on each other. Despite that, we each still feel like a single person. So how would it feel if we hooked up multiple people's brains together? Better yet, what if we hooked up one of our brains to the brain of someone in a computer simulation? Would we collectively feel like a single person then?

We won't know that until we actually try it. Right now we can't do that so we don't know the answer. I think it is reasonable to assume that the answer is yes, and the rest of my thought process assumes that the answer is yes too. If the answer is no then the rest of this writeup is completely irrelevant. I guess we'll find out in the not too distant future!

So let's say someone does that and they are now a single person that lives in both the real world and a virtual reality world. And then the part of the person living in the real world gets into a tragic accident and gets their brain blasted into a million pieces, and no more nondeterministic data (such as what the real world side of the person is thinking) is fed into the simulation. How unfortunate. But now they completely live in a virtual reality world that doesn't have to behave anything like our own! How awesome is that? Of course, the part of the person that was in the real world also happened to program the virtual reality simulation, and they transferred their knowledge to the virtual reality part of their brain when they got hooked up. So the person now in the virtual reality can still predict what will happen to them in terms of general relativity and the standard model, so in a sense they still really live in our universe.

By the way, I made another assumption there, which is that when the real world part of the brain got blasted into a million pieces, the person still lived on in the virtual reality world instead of just dying. I think this is a realistic assumption because people have done surgeries where they removed half of someone's brain and they still lived on OK. [https://en.wikipedia.org/wiki/Hemispherectomy] If this turns out not to hold true with part of the brain in the real world and part of the brain in a virtual reality world, then the rest of this writeup is completely irrelevant. I hope we'll find out about that in the not too distant future as well!

If these assumptions are correct, we now succeeded in getting someone from living completely in the real world to living to the greatest extent possible in a virtual reality world. If our technology progresses fast enough, that person may very well be you or me! And even though that person knows that they really live in a bigger universe that follows general relativity and the standard model, the virtual reality simulation sure *feels* convincing.

The problem

Now there's something that you can do with virtual reality simulations that I find really fascinating. I don't know how computers will work in 2060, but computers right now have dedicated places where they store their current state, such as memory and hard disks. It's possible to hibernate the computer so that its current state is frozen onto disk, copy the data on the disk to a second computer with the same specs, then start up both computers. If both computers operate correctly and the simulation is completely deterministic, then when the simulation resumes, it will behave the same way on both computers.

So suppose we do the following in our 2060-era hypothetical. In the virtual reality world, we put a clock on the wall. After disconnecting the real world part of the person, we copy the simulation to the second computer, then wait until the clock in the virtual world hits a certain time communicated in advance to the person inside (say, 12:00 midnight). From the time that we copy the simulation to the second computer until 12:00 midnight in the virtual world, both computers run the same deterministic simulation. Then at that moment the simulated clock hits 12:00 midnight, we destroy the computer with the original copy of the simulation, but leave the simulation running in the second computer.

From the perspective of the person we put in the simulation, there are 2 obvious possibilities that could happen when the clock strikes 12. If the person's identity is somehow tied to which physical computer he or she is in, then he or she "dies" and won't be able to perceive anything after that moment. On the other hand, if the person's identity is somehow tied to which simulation he or she is in in a way that has nothing to do with which computer is running it, then there is a possibility that he or she continues to "live on" because the same simulation is still running in the second computer.

If we do this and the person in the simulation "dies," then this doesn't raise any issues with our understanding of the universe. But the reason that I find this question so fascinating is the possibility that such people might "live on" in the second computer.

Suppose we do things a little differently, and we copy the simulation state into 2 other computers (instead of just 1) before destroying the original computer. If the person still finds that he/she is still alive after the virtual clock passes 12 midnight, then the person will know that he/she is in one of the two remaining computers, but will not know which one they're in because both computers are running the same simulation. So at this point, we give the person a way to tell which computer they're in by flashing a color in the virtual world, flashing red in one computer and green in the other. (The choice of which computer flashes which color can be delayed as long as possible to ensure that both computers have the same simulation state until that point.) If the plan to do this is communicated in advance to the person in the simulation, then this raises a new question for that person: how can he/she predict the probabilities of seeing a red flash or a green flash before it occurs?

Of course, he/she could predict that there's a 50% chance of seeing a red flash and a 50% chance of seeing a green one, but just because there's two possibilities doesn't necessarily mean that each possibility has a 50% chance of occurring. For example, if you consider the possibilities of whether or not you'll be struck by lightning within the next 10 seconds, it is far more likely that you will not be struck by lightning.

So, then, how should the person predict the probability of seeing a red or green flash? The most fundamental physics theories we know of today are general relativity, which describes physics at large scales, and the standard model of particle physics, which describes physics at small scales. Both theories have been experimentally tested to amazing precision, and the result of every experiment we've ever performed can be explained in terms of these theories. But if it is possible for people to go into computer simulations (a very big if, of course), then even if the poor souls know both theories and could somehow calculate in real-time how the individual subatomic particles in the computers would behave, they still could only predict in advance what each of the computers would do, not which of the computers they would personally find themselves in. So if it turns out that the person "survives" when the original computer is destroyed, our state-of-the-art physics theories would provide no guidance on predicting the probabilities of seeing a red or green flash, since this would require predicting which computer his or her identity "jumps" to.

As far as I am aware, as of 2015 there is not even a widely acknowledged guess inside the scientific community of what the outcome of this experiment would be from the perspective of the person in the simulation. Isn't that crazy? That sounds like it can't possibly be correct, doesn't it? But hopefully by now you have noticed a very serious problem with this "experiment." [reword to something like scientists are very smart so I'm sure they've thought of this before, so why haven't they answered it] Is it really an experiment?

Is this really an experiment?

In order to come up with a new rule for how the universe behaves, people use a process that works like this. First, you make a guess. (In this case, it's that people inside virtual reality simulations can "jump" between computers that run the same simulation.) Then, you figure out the consequences of the guess. (In this case, it's that people who go in virtual reality simulations can "survive" in a second computer if the original computer they go in is destroyed.) Then, you check whether those consequences are correct by comparing them to experience or experiment. (In this case, by putting yourself in a virtual reality simulation, having some friends copy the simulation to a second computer and destroy the original computer, and seeing if you survive when this happens.) If the predictions aren't consistent with the real world then the guess is wrong. [character of physical law; this is common knowledge but feynman does the best job at explaining it]

If it is possible for people to put themselves in virtual reality worlds, then for people who do that, this appears to be a completely valid experiment. But what about for people who watch the computers from outside? Normally, after people do an experiment, they announce the result to the rest of the world so that everyone else can know whether their guesses about the universe are wrong. But in this case, people watching from outside, including the entire scientific community on Earth, will see both the person that "dies" in the original computer and the copy of the person that "lives on" in the second computer, and won't be able to tell which outcome a person in the simulation would perceive! So is this really an experiment?

There is a similar issue with the possibility of putting a person's identity in a virtual reality simulation in the first place. If we hook up your brain with a simulated person's brain then blow up your real world brain, it would be obvious to you whether you survived in the virtual world. Those of us watching from outside could try to figure out whether you felt like you went from the real world to the virtual world by asking the simulated person if he or she is you. But does questioning the simulated person count as measuring the result of an experiment?

If these are considered to be experiments, it could potentially have serious implications for anyone trying to find a theory of everything [link] in physics. The most fundamental physics theories we know of today are the standard model and general relativity. The standard model makes extremely accurate predictions at small scales, but obviously wrong predictions at large scales. General relativity makes extremely accurate predictions at large scales, but obviously wrong predictions at small scales. The conventional wisdom is that if we discover a theory of "quantum gravity" that makes accurate predictions at both small and large scales, it would very likely be a theory of everything.

But if the hypotheticals above are considered experiments, then it would change all that. Not only would a physics theory have to unify the standard model and general relativity to be a candidate for a theory of everything, but it would also have to either predict the probability of people in virtual reality simulations "jumping" between computers or predict that such a situation is impossible. But I've never seen that mentioned in discussions of theories of everything.

I've had long discussions with friends about whether these should be considered experiments, but like many philosophical discussions, it tended to turn into a meaningless debate about what words such as "you" and "identity" mean. I'd love to hear what physicists think of this, and I wouldn't be surprised if they have thought of these hypotheticals but don't consider them to be experiments. [email link] But even though people who don't try to put themselves in simulations may never be able to experimentally confirm the outcomes of these hypotheticals, I think that giving up on predicting them would be unfair to people who do try to put themselves in simulations. And if our technology progresses quickly enough that I find myself inside a simulation in my lifetime, then I really want to have at least an educated guess of what I'd sense happening to me!

[if can't go into sim or "jump" probability is 0 then can still use gr+sm]
[if people can tell which computer they're in then it'd be no fun, so let's speculate about what if they can't; also consider how wrong diagram looks if people can tell which computer they're in]

So here's the problem. If we consider this to be a scientific question, then basically no one has a clue to what the answer to it is. Worse, the question is so general that it's difficult to find something that all situations like this have in common, and even if we came up with a guess of how to answer it, the people able to measure the answer a few decades from now would be unable to tell the rest of us the answer in a way that is helpful to us! So given that, what approaches can we take to try to answer this problem?

Well, consider what you would do if you were in that situation. Since we probably won't be able to perform this experiment for at least a few more decades, hopefully the scientific community will have one or more pretty good guesses of what you'll perceive happening by then. (Or perhaps the scientific community won't think that the question is scientific, but as stated earlier [state it earlier], I'm working on the assumption from now on that we do consider this to be scientific.) But since this will be the first time that you will be able to compare these predictions to observations, you should be very open to the possibility that these guesses will be wrong. And if it does turn out that these guesses are wrong, you should come up with your own guesses of what you will perceive happening, and continue the cycle of testing predictions and making new ones until you have a way of making predictions that seems to work.

So what would be the most useful thing to tell you if you were to be put in that situation? As for me personally, I'd imagine that a lot of what would happen to you would depend on the specific simulation you're put in, though a 50% chance of seeing a red flash and a 50% chance of seeing a green flash seems like a reasonable initial guess for the situation described previously. But if I were you, I wouldn't put much weight on that because I haven't experimentally verified that. [I just said the same thing 3 times] Indeed, since that would be the case for everyone else predicting what you would perceive happening the first time you're in that situation, it almost seems like the most useful thing to tell you would not be people's initial guesses of the probability of you seeing a red or green flash, but rather how you can quickly learn from the results once you start measuring them.

[we need to estimate subjective probabilities when underlying process picking flash color is unknown]

As it turns out, there is an entire field of study dedicated to studying processes that can be used to predict future outcomes from past ones. An important result that these people have mathematically proven is that there is one such way of doing this called algorithmic probability that is, in an important theoretical sense, "optimal!" The trouble is that it is impossible to calculate algorithmic probability with computers as we know them today because any computer program that tries to calculate it would run forever without ever producing a result, so there is an entire field of machine learning dedicated to finding more approximate learning algorithms that are practical to run on computers. But even though algorithmic probability is more or less impossible to use in practice, I think it is good to know it anyway because it's relatively simple and because it's pretty much the gold standard for inductive inference as long as you're not concerned about actually calculating it. So if we could hypothetically calculate it, how could it be applied to predict whether you'll see a red or green flash?

First of all, it's worth noting that even if we could calculate algorithmic probability, it would only be useful if we ran the color flashing experiment many times because the first few probabilities we'd come up with would be gibberish. Only when we have prior knowledge of previous outcomes can we take that knowledge into account in our predictions. So let's modify the setup accordingly. After putting the test subject (which might be you or me) in a computer simulation using the process described earlier, we pause the simulation, copy it onto a second computer, resume it on both computers, then flash red in the first computer and green in the second computer. (Or we could do the variation where we copy the simulation to 2 more computers, blow up the original computer, then flash red in the second computer and green in the third computer.) But this time we don't stop there. Next, we do the same thing to both computers. In other words, if we flashed red in computer A and green in computer B, we copy computer A's state to a new computer C, copy computer B's state into a new computer D, flash red in computers A and B, and flash green in computers C and D. Then we keep repeating this process of copying the simulation states into new computers, flashing red in the originals and flashing green in the copies, until we run out of computers or funding or whatever.

[picture]

Now in order to bring algorithmic probability into the picture, we first need to introduce the concept of bitstrings. When you have a string of text, that text is stored in the computer as a sequence of 1's and 0's called a bitstring. To convert the bitstring to characters, you apply something called a character encoding. One common encoding is called ASCII, and to convert a bitstring to ASCII characters, you separate the bitstring into 8 bit chunks called bytes, and use a table to find the character corresponding to each byte.

[motivation is less random bitstrings seem more likely]

So here's how to determine the algorithmic probability that the person in the simulation will see a particular sequence of colored flashes. Suppose we make a bitstring by repeatedly flipping a fair coin, writing 0 each time we get heads and 1 each time we get tails. (By fair coin, I mean that each flip has a 50% chance of being heads or tails and every flip is independent of the others.) After writing down each result, we decide whether to continue by flipping a second coin. When we stop flipping, we make a binary file with the bits we wrote down, then use a C compiler to *try to compile it*. If we get a compile error (which we almost definitely will), we keep repeating this procedure to generate random C files until one of them compiles successfully. When that finally happens, we run the resulting program in a deterministic way with access to unlimited memory and see what it prints out to the console. Now this console output can be considered a bitstring too, so we take 0 to mean "red flash" and 1 to mean "green flash." Then the algorithmic probability that the person in the simulation will see a particular sequence of colored flashes is the probability that a console output bitstring generated this way begins with that particular sequence. [reword last sentence, redirect std out to file so don't need bitstring explanation]

[are there any issues caused by finite console outputs?]

Or, in a flowchart:

[flowchart]

Isn't that procedure ridiculous? In essence, the algorithmic probability of a bitstring (which can be interpreted as a sequence of red and green flashes) is the probability that it is the beginning of the output of a randomly generated program!

Now of course, you may wonder, is that *really* the probability of what might happen to us if we put ourselves in a computer simulation and couldn't tell which computer we were in?

Honestly, I don't know. The only reason I bring up this possibility is because if it's possible to answer that question by experiment, then as far as I can tell the scientific community does not have an agreed upon prediction of what the answer to it is. And as someone who is likely to see these super-powerful computers exist in my lifetime, I feel we have an obligation to try to answer it, or at least participate in wild-eyed speculation of what the consequences would be. I am just trying to start that discussion. So please do not consider me to be an authority or representative of the scientific community on this subject (because I'm not), and if you want to add to this discussion, I'm more than happy to hear what your thoughts are.

But it's worth mentioning a few things about using algorithmic probability this way.

[is this actually a semi measure? yes according to http://scholarpedia.org/article/Algorithmic_probability, no according to https://en.wikipedia.org/wiki/Solomonoff's_theory_of_inductive_inference]

[how to use as learning algorithm]
[can use other info to predict flash colors by e.g. videotaping everything you see and using it to predict what you'll see next (can do that in real world too)]
[why single out solomonoff induction instead of other learning algorithms? several theoretical reasons for this, but to make long story short it is arguably the best learning algorithm theoretically possible if you have unlimited computing power, give links to more info]
[speculation: output of program is in a sense a "type" because it's something we know about the program, so wondering if possible to relate to gr & qm using shared relationship with category theory]

for next post:

For one, you could do the same procedure with a different Turing complete language than C and get different resulting probabilities, and that would still be considered "algorithmic probability."

I know what you're thinking. "See, algorithmic probability isn't unique. So even if these probabilities can be determined by experiment in the first place, algorithmic probability can't even tell me what are the 'right' probabilities to expect. So this isn't scientific."

Well, not so fast. No matter which programming language you pick, all these different choices of algorithmic probability have more in common than you might expect, and here's why. Since there's a 50% chance that each new bit we write will be the end of the bitstring, the shortest programs that print a given color flashing sequence will have by far the biggest contribution to its probability. For short color sequences, the shortest program that prints it just prints it directly. For long but predictable color sequences, the shortest program that prints it may use a simple algorithm. For example, to print 1000 'A' characters, it is shorter to write a loop to print 'A' 1000 times than to print a string of 1000 'A's. But if the color sequence is both complicated and highly compressible, the shortest program in a given language that prints it may not be completely written in that language!

What do I mean by that? If you've ever taken a program written in one language and rewritten it in a different language, you may have noticed that the length of a program can wildly vary depending on which language it's written in. For example, if a C program is rewritten in Lisp or Python, it is not uncommon for the Lisp or Python program to be several times shorter than the original C program, even though both programs do the same thing. So how can we take advantage of that to write shorter code?

One of the fascinating properties about a Turing complete language like C is that it is possible to write a program called an interpreter to simulate any other programming language that a computer can run. These interpreters can be surprisingly short; for example the interpreter for a language called PicoLisp is written in less than 16,000 lines of C. So suppose we have a 500,000 line C program that we want to rewrite using the least code we can. We know that the same program can be written in, say, 50,000 lines of PicoLisp, but there is a requirement that our code is written in C. If we're feeling clever, we can simply write a C program that includes the PicoLisp headers, stores the 50,000 lines of PicoLisp in a string constant, then runs the PicoLisp code in the interpreter. Our new program would then be approximately 16,000 + 50,000 = 66,000 lines of code, much shorter than the original 500,000 line program, and it would still technically be written in C even though most of its code is actually written in PicoLisp!

#include "pico.h"
char* code = "50,000 lines of PicoLisp";
int main(void) {
    run_my_picolisp_code(code); // FYI, this isn't actually how you run PicoLisp code [check how to actually do it]
    return 0;
}

[AI for games: "minischeme is less than 2500 lines of C code for the complete system, although it lacks some of the more exotic features of a full scheme implementation"]

This crazy-sounding strategy of embedding one programming language in another is actually pretty common. For example, many popular languages do not have good built-in syntax to handle string matching or database queries. A common workaround is to import a regular expression or SQL library, then pass regular expressions or SQL code into the library functions as a string, just like we did with PicoLisp in the example above.

[non-unique probabilities, converging (and why), only way to get result faster would be by overfitting, classifying result that doesn't fit, lead in to prior info]
[this is basically a mathematical theory that if we do the scientific method in a certain idealized way then our process of learning will always have certain characteristics, what's testable about it is whether that idealized process of learning is representative of how we do it in real world?]
[relationship to category theory: http://math.ucr.edu/home/baez/rosetta_fresno.pdf]
