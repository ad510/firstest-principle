how maximize entropy = make lots of copies of yourself:
- fast approximation of entropy-maximizing AIXI using type systems
  - output bitstring -> type of programming language
    - programming language = function from program to unknown part of output
      - type of program = either AND-ed axioms (simpler) or probability distribution over all possible axioms (more accurate)
      - function = graph of atomic steps between types (A ^ B ^ C takes 2 steps) [intersection type isn't a function call]
    - observations, actions, etc become types
[how does solomonoff induction work at this point? maybe bayes thm or quantum something on axioms? I suspect you still need to estimate entropy of type, and not clear how that relates to copying stuff]
  - reward function -> estimation of reward function based on types
    - maximize entropy -> recursively maximize # possible future actions [wrong or vague]
- make lots of copies of yourself = recursively maximize # possible future actions (maximize out degree) = maximize entropy
- caching = making copies of things that may potentially become "you" in the near future (maximize in degree)

- real life AGI might work similarly to this fast approximation of entropy-maximizing AIXI
- lifetime = algorithmic probability expects output to have finite entropy = some type systems have finite # types
  - in theory entropy-maximizing AIXI tries to avoid dying
  - is that true in practice?
  - relationship to black holes?
- self-improvement = improve the type system and/or entropy estimation over time
  - but how?
