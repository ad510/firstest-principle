how maximize entropy = make lots of copies of yourself:
- fast approximation of entropy-maximizing AIXI using type systems
  - bitstring -> type of programming language
    - programming language = function from program to unknown part of output
    - program = either AND-ed axioms (simpler) or probability distribution over all possible axioms (more accurate)
    - observations, actions, etc become types
  - reward function -> estimation of reward function based on types
    - maximize entropy -> recursively maximize # possible future actions
      - # possible actions can vary in consistent proof system, unlike turing complete programming language
- make lots of copies of yourself = recursively maximize # possible future actions (maximize out degree) = maximize entropy
- caching = making copies of things that may potentially become "you" in the near future (maximize in degree)

- real life AGI might work similarly to this fast approximation of entropy-maximizing AIXI
- lifetime = algorithmic probability expects output to have finite entropy = some type systems have finite # types
  - in theory entropy-maximizing AIXI tries to avoid dying
  - is that true in practice?
  - relationship to black holes?
- self-improvement = improve the type system and/or entropy estimation over time
  - but how?
